import json
import os
import re
from urllib.parse import urlparse

def extract_anime_id(url: str) -> str:
    """
    Tá»± Ä‘á»™ng láº¥y anime_id tá»« URL.
    VÃ­ dá»¥: https://vuighe.cam/naruto/ -> naruto
    """
    # XÃ³a dáº¥u gáº¡ch chÃ©o cuá»‘i náº¿u cÃ³
    url = url.strip().rstrip('/')
    
    # Láº¥y pháº§n cuá»‘i cÃ¹ng cá»§a URL
    path_parts = url.split('/')
    anime_id = path_parts[-1]
    
    # Náº¿u user lá»¡ copy link táº­p phim (vÃ­ dá»¥: .../naruto/tap-1), hÃ£y cáº¯t bá» pháº§n 'tap-1'
    if "tap-" in anime_id:
        anime_id = path_parts[-2]
        
    return anime_id

def clean_base_url(url: str) -> str:
    """
    Äáº£m báº£o URL base sáº¡ch Ä‘áº¹p Ä‘á»ƒ ná»‘i chuá»—i
    """
    url = url.strip().rstrip('/')
    # Náº¿u URL káº¿t thÃºc báº±ng 'tap-xxx', cáº¯t bá» nÃ³ Ä‘i Ä‘á»ƒ láº¥y root
    if re.search(r'/tap-\d+$', url):
        url = re.sub(r'/tap-\d+$', '', url)
    return url

def main():
    print("="*50)
    print("ğŸ› ï¸  CÃ”NG Cá»¤ Táº O CONFIG CRAWLER Tá»° Äá»˜NG")
    print("="*50)

    # 1. Nháº­p URL
    while True:
        url_input = input("ğŸ‘‰ Nháº­p link Anime (VD: https://vuighe.cam/chu-thuat-hoi-chien-phan-2/): ").strip()
        if url_input.startswith("http"):
            break
        print("âŒ URL khÃ´ng há»£p lá»‡! Pháº£i báº¯t Ä‘áº§u báº±ng http hoáº·c https.")

    # 2. Nháº­p sá»‘ táº­p
    while True:
        try:
            start_ep = int(input("ğŸ‘‰ Tá»« táº­p sá»‘: "))
            end_ep = int(input("ğŸ‘‰ Äáº¿n táº­p sá»‘: "))
            if start_ep > 0 and end_ep >= start_ep:
                break
            print("âŒ Sá»‘ táº­p khÃ´ng há»£p lá»‡ (Pháº£i > 0 vÃ  'Äáº¿n táº­p' >= 'Tá»« táº­p')")
        except ValueError:
            print("âŒ Vui lÃ²ng nháº­p sá»‘ nguyÃªn.")

    # 3. Xá»­ lÃ½ dá»¯ liá»‡u
    anime_id = extract_anime_id(url_input)
    base_url = clean_base_url(url_input)
    
    print(f"\nâœ… ÄÃ£ nháº­n diá»‡n Anime ID: {anime_id}")
    print(f"âœ… Base URL: {base_url}")

    episodes_list = []
    for i in range(start_ep, end_ep + 1):
        # Quy táº¯c link cá»§a VuiGhe: base_url + /tap-i
        ep_url = f"{base_url}/tap-{i}"
        episodes_list.append({
            "episode": i,
            "url": ep_url
        })

    # 4. Táº¡o cáº¥u trÃºc JSON
    config_data = {
        "output_dir": "./data/raw_videos",
        "headless": True,
        "delay_between_episodes": 5,
        "anime": [
            {
                "anime_id": anime_id,
                "season": "",  # Äá»ƒ trá»‘ng hoáº·c báº¡n cÃ³ thá»ƒ input thÃªm náº¿u muá»‘n
                "episodes": episodes_list
            }
        ]
    }

    # 5. LÆ°u file
    output_filename = f"config_{anime_id}.json"
    with open(output_filename, 'w', encoding='utf-8') as f:
        json.dump(config_data, f, indent=2, ensure_ascii=False)

    print("\n" + "="*50)
    print(f"ğŸ‰ ÄÃ£ táº¡o xong file config: {output_filename}")
    print(f"ğŸ“‚ Tá»•ng sá»‘ táº­p: {len(episodes_list)}")
    print("="*50)
    print(f"\nğŸš€ Äá»ƒ cháº¡y crawler, hÃ£y dÃ¹ng lá»‡nh:")
    print(f"   python run_crawler.py --config {output_filename}")

if __name__ == "__main__":
    main()