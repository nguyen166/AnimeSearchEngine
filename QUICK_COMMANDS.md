# âš¡ Quick Setup Commands - AnimeSearchEngine

## ğŸš€ Setup tá»« Ä‘áº§u (5 phÃºt)

```powershell
# 1. Clone & Navigate
cd d:\2025-2026\Term1\IR\AnimeSearchEngine\AnimeSearchEngine

# 2. Create Virtual Environment
python -m venv venv
.\venv\Scripts\activate

# 3. Install Dependencies
pip install -r requirements.txt

# 4. Start Databases (Docker)
docker-compose up -d
Start-Sleep -Seconds 120  # Äá»£i DB ready

# 5. Create .env file
copy .env.example .env
notepad .env  # ThÃªm GEMINI_API_KEY

# 6. Create Data Folders
mkdir data, data\videos, data\frames

# 7. Start API Server
python -m uvicorn app.main:app --reload
```

**Done!** API running at http://localhost:8000/docs

---

## ğŸ”§ Daily Commands

### Start Working:
```powershell
cd d:\2025-2026\Term1\IR\AnimeSearchEngine\AnimeSearchEngine
.\venv\Scripts\activate
docker-compose up -d
python -m uvicorn app.main:app --reload
```

### Stop Working:
```powershell
# Ctrl+C to stop API server
docker-compose down
deactivate
```

---

## ğŸ“¦ Data Ingestion

### Create Config:
```powershell
python scripts/integrated_pipeline.py --create-sample config_crawl.json
```

### Edit config_crawl.json:
```json
{
  "anime": [{
    "anime_id": "anime_001",
    "title": "Anime Title",
    "episodes": [
      {
        "episode": 1,
        "crawl_url": "https://vuighe.cam/anime/tap-1/",
        "fps": 1.0
      }
    ]
  }]
}
```

### Run Pipeline:
```powershell
python scripts/integrated_pipeline.py --config config_crawl.json
```

---

## ğŸ§ª Test Commands

```powershell
# Test health
curl http://localhost:8000/health

# Test translation
curl -X POST "http://localhost:8000/translate?text=xin+chÃ o"

# Test search
curl -X POST http://localhost:8000/search/temporal `
  -H "Content-Type: application/json" `
  -d '{"current_action":"explosion","previous_action":"attack","time_window":10,"top_k":5}'

# Check stats
curl http://localhost:8000/stats
```

---

## ğŸ› Fix Common Errors

### "Cannot activate venv":
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### "Docker not running":
```powershell
# Open Docker Desktop
Start-Process "C:\Program Files\Docker\Docker\Docker Desktop.exe"
Start-Sleep -Seconds 30
docker ps
```

### "Port 8000 in use":
```powershell
# Kill process
netstat -ano | findstr :8000
taskkill /PID <PID> /F
```

### "Milvus connection failed":
```powershell
docker-compose down
docker-compose up -d
Start-Sleep -Seconds 120
```

---

## ğŸ“Š Verify Setup

```powershell
# All must return success âœ…

# 1. Python version
python --version

# 2. Virtual env active
Get-Command python | Select-Object Source  # Should point to venv

# 3. Docker services
docker ps | findstr "milvus"
docker ps | findstr "elasticsearch"

# 4. API health
curl http://localhost:8000/health

# 5. Database connections
curl http://localhost:19530
curl http://localhost:9200
```

---

## ğŸ”‘ Get Gemini API Key

1. Visit: https://makersuite.google.com/app/apikey
2. Login with Google
3. Click "Create API Key"
4. Copy to `.env`:
   ```env
   GEMINI_API_KEY=your_key_here
   ```

---

## ğŸ“ Project Structure

```
AnimeSearchEngine/
â”œâ”€â”€ .env                     # Config (add GEMINI_API_KEY here)
â”œâ”€â”€ docker-compose.yml       # Database services
â”œâ”€â”€ requirements.txt         # Python packages
â”œâ”€â”€ app/                     # Source code
â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â”œâ”€â”€ config.py           # Settings
â”‚   â”œâ”€â”€ core/               # DB connections
â”‚   â”œâ”€â”€ services/           # Business logic
â”‚   â”œâ”€â”€ routers/            # API endpoints
â”‚   â””â”€â”€ models/             # Data schemas
â”œâ”€â”€ scripts/                 # Tools
â”‚   â”œâ”€â”€ integrated_pipeline.py  # Crawl + Ingest
â”‚   â”œâ”€â”€ ingest_anime.py         # Ingest only
â”‚   â””â”€â”€ crawler.py              # Crawl only
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ videos/             # Downloaded videos (temp)
â”‚   â””â”€â”€ frames/             # Extracted frames (permanent)
â””â”€â”€ venv/                   # Virtual environment
```

---

## ğŸ¯ Workflow

```
1. Activate venv â†’ Start Docker â†’ Start API
2. Create crawl config
3. Run pipeline (crawl â†’ ingest â†’ cleanup)
4. Test search via API docs
5. Monitor stats
```

---

## ğŸ“š Full Docs

- **Setup:** [SETUP_GUIDE.md](./SETUP_GUIDE.md)
- **Pipeline:** [INTEGRATED_PIPELINE.md](./INTEGRATED_PIPELINE.md)
- **Translation:** [GEMINI_TRANSLATION.md](./GEMINI_TRANSLATION.md)

---

**Hotline:** Check [SETUP_GUIDE.md](./SETUP_GUIDE.md) for detailed troubleshooting! ğŸ†˜
